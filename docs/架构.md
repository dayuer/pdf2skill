# pdf2skill 系统架构设计

> 将非结构化文档（PDF）转化为大模型外挂工具库（Agent Skills）的 ETL 流水线。

---

## 一、系统定位

pdf2skill 的核心目标是将人类可读的连续文本，**降维并重构**为机器（Claude Code / OpenClaw）易于调用的结构化逻辑树。

**输入**：任意 PDF 文档（技术手册、方法论书籍、操作规范）
**输出**：一组符合目标 Agent 框架规范的 `.md` Skill 文件 + `index.md` 路由表

---

## 二、技术栈选型

| 层级           | 技术选型                        | 选型理由                                                      |
| -------------- | ------------------------------- | ------------------------------------------------------------- |
| 文档解析引擎   | MinerU                          | PDF→Markdown 保留排版结构和公式，双栏/图文混排处理能力强      |
| 逻辑推理大模型 | DeepSeek R1                     | 强化学习带来的长思维链（CoT），复杂逻辑抽取和规则重构表现优异 |
| 低成本粗筛模型 | 通义千问长文本版 / 本地小模型   | 语义密度评分，降低 Token 消耗                                 |
| 向量编码模型   | bge-m3 / text-embedding-3-small | 规则去重聚类                                                  |
| 后端框架       | Python + FastAPI                | 流转控制                                                      |
| 异步任务队列   | Celery + Redis                  | 长时间处理任务的异步调度                                      |

---

## 三、核心架构：Schema-First + Two-Layer RAPTOR 混合

经过多轮评估，最终确定的架构融合了三种方案的优势：

- **动态 Schema 逆向驱动**：先约束输出空间，后执行提取，抑制幻觉
- **两层 RAPTOR**：叶子→根的两级聚合，兼顾上下文和成本
- **Critic 角色**：内嵌于 Reduce 阶段的逻辑审查

### 数据流总览

```
PDF 文件
  │
  ▼
┌──────────────────────────────────────────────────────┐
│           Phase 0: Schema Genesis                    │
│  MinerU 提取 TOC + 前言 → R1 → 生成 Skill Schema    │
│  （支持人工 Override）                                │
└────────────────────────┬─────────────────────────────┘
                         │ Schema 模板
                         ▼
┌──────────────────────────────────────────────────────┐
│       Phase 1A: 物理版面降维 (MinerU 预处理)          │
│  PDF → Markdown → 噪音清洗（页眉页脚/致谢/参考书目） │
└────────────────────────┬─────────────────────────────┘
                         │ 干净 Markdown
                         ▼
┌──────────────────────────────────────────────────────┐
│       Phase 1B: 语义语法树切分 (AST Chunking)         │
│  Markdown AST 解析 → 按标题层级切分 → 父级上下文注入  │
│  → 字数卡点二次切分 → 降级策略兜底                    │
└────────────────────────┬─────────────────────────────┘
                         │ N 个结构化文本块
                         ▼
┌──────────────────────────────────────────────────────┐
│     Phase 1C: 语义密度粗筛 (双通道评估)               │
│  通道 A（独立价值）：操作步骤/方法论评分 1-5          │
│  通道 B（上下文锚点）：作用域/前提条件/术语定义检测    │
│  → 丢弃通道 A ≤ 2 且通道 B 无价值的块                │
└────────────────────────┬─────────────────────────────┘
                         │ M 个高价值文本块
                         ▼
┌──────────────────────────────────────────────────────┐
│      Phase 2: Constrained Extraction (并行 Map)      │
│  Schema + 文本块 → R1 → 结构化 Skill 填充            │
│  → <think> 标签丢弃（仅取最终结论）                   │
│  → SkillValidator 三重校验                            │
│     ├── 格式校验（YAML/JSON 可解析）                  │
│     ├── 完整性校验（必填字段存在）                     │
│     └── 幻觉初筛（关键词交叉检查）                    │
└────────────────────────┬─────────────────────────────┘
                         │ N 个 Raw Skills
                         ▼
┌──────────────────────────────────────────────────────┐
│      Phase 3: Reduce + Critic (两层 RAPTOR)          │
│  ┌─ 向量编码（bge-m3）→ 余弦相似度 ≥ 0.88 聚类      │
│  ├─ R1 Reduce：合并同类项，消解逻辑冲突              │
│  └─ R1 Critic（同一调用）：审查逻辑闭环，检测遗漏    │
│  → 输出去重后的 Final Skills                         │
└────────────────────────┬─────────────────────────────┘
                         │ Final Skills
                         ▼
┌──────────────────────────────────────────────────────┐
│         Phase 4: Skill Packaging                     │
│  生成 index.md 路由表 → 写入 .md 文件集              │
│  → ZIP 打包输出                                      │
└──────────────────────────────────────────────────────┘
```

---

## 四、Skill Schema 定义

每个 Skill 文件使用 YAML Frontmatter + Markdown Body 结构：

```yaml
# --- Skill Frontmatter ---
name: evaluate-stock-safety-margin    # kebab-case，全局唯一
trigger: "当用户要求评估某只股票是否具备安全边际时"
domain: value-investing               # 所属领域，用于路由表分组
prerequisites:                         # 前置依赖
  - "需要获取目标股票近5年财报数据"
source_ref: "《聪明的投资者》第8章 第3节"  # 溯源锚点
confidence: 0.85                       # 提取置信度
prompt_version: "v0.1"                 # 生成此 Skill 的 Prompt 模板版本
---

# 执行步骤

1. 获取近 5 年平均 ROE
2. **IF** ROE < 15% → 输出「盈利能力不足，不建议继续评估」→ **终止**
3. 计算自由现金流折现值（DCF），折现率取 10%
4. **IF** 当前股价 < DCF × 0.7 → 输出「具备安全边际，可进入深度分析」
5. **ELSE** → 输出「估值偏高，建议等待股价回调至 {DCF × 0.7} 以下」

# 输出格式要求

以结构化表格呈现：股票代码、ROE、DCF估值、当前价格、安全边际判断。
```

### Skill 粒度标准

一个 Skill 应对应一个**完整的决策流程**（Decision Process）：

- ✅ 给定一个具体场景，经过 2-5 步判断，得出一个可执行结论
- ❌ 不是一个函数调用（太细）
- ❌ 不是一本书的摘要（太粗）

---

## 五、各阶段实现细则

### Phase 0: Schema Genesis

**输入**：MinerU 提取的目录（TOC）+ 前言/引言
**输出**：该书专属的 Skill Schema 模板（定义字段集合）

**执行逻辑**：

1. 将 TOC + 前言单独喂给 R1
2. R1 根据书籍类型自动生成 JSON Schema —— 定义「这本书应该包含哪些核心组件、常见故障、核心公式」
3. 人工可选介入：补充/修正/删除 Schema 字段

**降级策略**：当 TOC 信息不足（叙事类书籍），人工提供预设 Schema 模板。

### Phase 1A: 物理版面降维

**工具**：MinerU
**清洗规则**（Python 正则/关键词匹配）：

- 删除页眉页脚、纯数字页码行
- 删除参考书目章节（关键词：`参考文献`、`References`、`Bibliography`）
- 删除致谢章节（关键词：`致谢`、`Acknowledgments`）
- 丢弃纯图片文件，保留 Markdown 内嵌的表格和公式

### Phase 1B: 语义语法树切分 (AST Chunking)

**核心原则**：基于 Markdown 标题层级，而非字符长度。

**切分算法**：

1. 解析 Markdown AST，以 `##`（二级标题）或 `###`（三级标题）为边界切分逻辑块
2. 为每个分块注入父级上下文头部：
   ```
   > 文档：《XXX》 | 章节：第三章 数据库迁移 | 小节：3.2 预检清单
   ```
3. 字数卡点：若单块超过 **4000 字**（R1 最佳推理窗口），向下寻找四级标题或段落换行符进行二次切分
4. 过短合并：若单块少于 **200 字**，向上合并至前一个块

**降级策略**（三级 Fallback）：

```
IF 标题数量 ≥ 5 → 正常 AST 切分
ELIF 标题数量 < 5 BUT 段落清晰 → 按段落边界 + 字数上限切分
ELSE（纯文本墙）→ 滑动窗口切分（窗口 3000 字，重叠 20%）
```

### Phase 1C: 语义密度粗筛

**模型**：低成本模型（通义千问 / 本地部署）
**双通道评估**：

| 通道            | 评估维度                             | 保留条件       |
| --------------- | ------------------------------------ | -------------- |
| A（独立价值）   | 是否包含操作步骤、方法论、规则、参数 | 评分 ≥ 3/5     |
| B（上下文锚点） | 是否定义作用域、前提条件、术语       | 检测到锚点标记 |

**丢弃规则**：仅当通道 A ≤ 2 **且** 通道 B 无锚点时丢弃。

### Phase 2: Constrained Extraction

**模型**：DeepSeek R1
**并发策略**：异步 I/O 并发请求，带指数退避重试机制

**Prompt 工程规范**：

- 角色设定：「你是一个严苛的系统架构师和逆向工程专家」
- 输入：Schema 模板 + 文本块 + 父级上下文
- 输出约束：仅允许输出符合 Schema 字段的 YAML Frontmatter + Markdown Body
- 幻觉抑制：「仅允许使用原文中明确出现的值，若原文未提供某个参数，强制填入 null」
- 话痨抑制：「直接输出最终数据结构，禁止输出任何过渡性语言」
- `<think>` 处理：解析 API 返回值，丢弃 `<think>...</think>` 标签内容，仅取最终输出

**SkillValidator 三重校验**：

| 校验层     | 检查内容                           | 失败处理                             |
| ---------- | ---------------------------------- | ------------------------------------ |
| 格式校验   | YAML Frontmatter 可解析            | 正则修复 → 重试 1 次 → 标记失败      |
| 完整性校验 | `name`, `trigger`, 执行步骤存在    | 标记为「不完整」，跳过               |
| 幻觉初筛   | 步骤中关键术语是否在输入文本中出现 | 标记为「疑似幻觉」，进入人工审核队列 |

**表格专用策略**：检测文本块中 Markdown 表格占比 > 50% 时，启用专用 Prompt —— 要求 R1 先将表格转为键值对，再提取逻辑。

### Phase 3: Reduce + Critic

**向量去重**：

- 编码模型：bge-m3
- 相似度阈值：余弦相似度 ≥ 0.88
- 实现：内存中 numpy 暴力搜索（规模 < 500 条，无需 FAISS）
- 聚类方式：基于相似度的贪心聚类

**R1 二次处理**（Reduce + Critic 合并为单次调用）：

- Reduce 指令：「合并以下同主题规则，消除矛盾点和重复步骤，输出唯一标准操作流程」
- Critic 指令：「审查逻辑闭环：每个步骤是否有明确的前置条件？是否存在未处理的分支？缺少前置条件时，补充说明」

### Phase 4: Skill Packaging

- 将 Final Skills 写入 `.md` 文件（一个 Skill 一个文件）
- 自动生成 `index.md` 路由表，按 `domain` 分组
- 使用 Python `zipfile` 打包为 ZIP

---

## 六、可观测性设计

**每次 R1 调用自动记录一条日志**：

```json
{
  "run_id": "uuid",
  "phase": "extraction | reduce | critic",
  "prompt_version": "v0.5",
  "input_chunk": "原文文本（前 500 字）...",
  "input_metadata": { "book": "xxx", "chapter": "3.2", "chunk_index": 7 },
  "output_raw": "R1 原始输出...",
  "output_parsed": { "name": "...", "trigger": "..." },
  "think_tokens": 1234,
  "output_tokens": 567,
  "validation_result": "pass | fail_format | fail_incomplete | fail_hallucination",
  "human_label": null,
  "timestamp": "ISO8601"
}
```

日志持久化为 JSONL 文件，按书籍/日期分目录存储。

---

## 七、自动化提示词进化系统（M4 里程碑）

> [!IMPORTANT]
> 此模块在基线 Pipeline 跑通 + 积累 ≥ 50 条人工标注日志后启动。

### 双 Agent 架构

| 角色                | 职责                                   | 模型        |
| ------------------- | -------------------------------------- | ----------- |
| Generator（执行者） | 使用当前 Prompt 处理文本块，输出 Skill | DeepSeek R1 |
| Optimizer（进化器） | 分析失败案例，重写 Prompt              | DeepSeek R1 |

### 进化器输入协议

```json
{
  "source_text": "原始文本片段",
  "current_prompt": "当前提取提示词",
  "bad_output": "当前 Prompt 产生的错误结果",
  "human_feedback": {
    "tag": "格式崩溃 | 遗漏核心步骤 | 存在捏造幻觉 | 包含多余废话 | 其他",
    "comment": "可选的自由文本补充，当标签为'其他'时必填"
  }
}
```

### 变异规则

| 反馈标签     | 进化方向                                            |
| ------------ | --------------------------------------------------- |
| 格式崩溃     | 加入严格 JSON/YAML 结构声明 + 绝对格式禁令          |
| 遗漏核心步骤 | 增加「强制预检步骤」—— 先列出条件触发词和动作动词   |
| 存在捏造幻觉 | 极端收敛指令 —— 仅使用原文明确出现的值，缺失填 null |
| 包含多余废话 | 禁止过渡性语言的绝对禁令                            |
| 其他         | 根据 comment 自行推断根因                           |

### 全局护栏

进化器生成的新约束不得违反：

1. 允许语义等价的同义词替换
2. 不限制执行者对原文逻辑的重组能力
3. 每条新增约束必须可程序化验证

### 替换策略

新 Prompt **不是**单样本通过即替换。必须满足：

1. ✅ 在失败样本上通过
2. ✅ 在历史通过样本中随机抽 2 个也通过（回归测试）
3. 两项均满足 → 替换；否则 → 保留旧 Prompt，新 Prompt 标记为「候选」

Prompt 历史链全量保留，支持随时回滚。

---

## 八、工程风险与防范

| 风险                                   | 防范措施                                         |
| -------------------------------------- | ------------------------------------------------ |
| PDF 解析质量不可控（扫描版/水印/多栏） | Phase 1A 后人工抽检 10% 文本块，错误率 > 5% 退回 |
| R1 长文本注意力衰减                    | 严格分块 + 上下文注入，单块不超过 4000 字        |
| R1 输出幻觉                            | Schema 约束 + SkillValidator 三重校验 + 溯源锚点 |
| API 速率限制                           | 指数退避重试（初始 1s, 最大 60s, 最多 5 次）     |
| R1 `<think>` Token 成本                | 丢弃思考过程，确认 API 计费口径                  |
| Prompt 进化退化                        | 版本链 + 回归测试 + 随时回滚                     |
| 跨章节知识碎片                         | 父级上下文注入 + Phase 3 向量聚类缝合            |

---

## 九、渐进式落地里程碑

| 里程碑                    | 周期 | 交付物                                | 验收标准                               |
| ------------------------- | ---- | ------------------------------------- | -------------------------------------- |
| **M1: 手动验证**          | 1 周 | Prompt v0.5 + 粒度标准 + 失败模式分类 | 手动处理 1 本书，人工评估 Skill 可用性 |
| **M2: 半自动 Pipeline**   | 2 周 | Phase 1A-1C 自动化 + Phase 2 半自动   | 3-5 本不同类型书籍通过测试             |
| **M3: 全自动 + 质量闭环** | 3 周 | 全 Pipeline 自动化 + 可观测性日志     | 端到端处理一本书，无人工干预           |
| **M4: 进化器上线**        | 2 周 | Auto-Prompting 双 Agent 系统          | 积累 ≥ 50 条标注后，Prompt 自动进化    |

---

## 十、成本估算（300 页技术书籍）

| 阶段            | 模型      | Token 消耗           | DeepSeek R1 单价   | 成本           |
| --------------- | --------- | -------------------- | ------------------ | -------------- |
| Phase 0: Schema | R1        | ~30K in + ~10K out   | ¥4/M in, ¥16/M out | ≈ ¥0.3         |
| Phase 1C: 粗筛  | 本地/千问 | ~200K in             | ≈ ¥0               | ≤ ¥0.5         |
| Phase 2: 提取   | R1        | ~500K in + ~200K out | 同上               | ≈ ¥5.2         |
| Phase 3: Reduce | R1        | ~100K in + ~50K out  | 同上               | ≈ ¥1.2         |
| 验证/重试       | R1        | ~150K in + ~50K out  | 同上               | ≈ ¥1.4         |
| **合计**        |           |                      |                    | **≈ ¥8-10/本** |

> [!NOTE]
> 若使用 Claude 3.5 Sonnet 替代 R1，成本约为 ¥100-150/本（15-20 倍）。
